{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "verification.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kFDbAj3hOsE",
        "outputId": "b8bba99a-c00b-4520-9fb2-e5c41ed49905"
      },
      "source": [
        "!pip install timm foolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/89/d94f59780b5dd973154bf506d8ce598f6bfe7cc44dd445d644d6d3be8c39/timm-0.4.5-py3-none-any.whl (287kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 5.8MB/s \n",
            "\u001b[?25hCollecting foolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ff/1ba817ad9aa7c2ca28fb809d64939bee7311e3e62fdd87c4011232c4640e/foolbox-3.3.1-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Collecting requests>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Collecting GitPython>=3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (56.0.0)\n",
            "Collecting eagerpy==0.29.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/07/54994565da4fc5a4840d3a434fb9bf3835b4a4e68c931ccfcc327d568f95/eagerpy-0.29.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: timm, requests, smmap, gitdb, GitPython, eagerpy, foolbox\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed GitPython-3.1.14 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.7 requests-2.25.1 smmap-4.0.0 timm-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UAUIWRjhVys",
        "outputId": "4db3f46b-109f-421c-ff27-d9aa6bf95454"
      },
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjIoX6cjhWSF",
        "outputId": "d97e5fd8-8072-4f13-cc11-dd60f7115991"
      },
      "source": [
        "#@title Imports\n",
        "\n",
        "import eagerpy as ep\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import L2PGD\n",
        "\n",
        "import timm\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.8.1+cu101\n",
            "Torchvision Version:  0.9.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwKys30DhX12"
      },
      "source": [
        "#@title Global Variables\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "input_size = 224\n",
        "feature_extract = False\n",
        "num_epochs = 5\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGPAmRldhdEh"
      },
      "source": [
        "#@title Model\n",
        "model = models.resnet18(pretrained=False)\n",
        "num_ftr = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftr, num_classes)\n",
        "\n",
        "# load weights\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/598dataset/Detector_ResNet50.pth'))\n",
        "\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdUighlHiW30"
      },
      "source": [
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/tinyImageNet/TinyImageNet'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, \"tiny_\"+x),\n",
        "                                          transform[x])\n",
        "                  for x in ['train', 'val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiK-95QJkmaB",
        "outputId": "450d041f-44ce-46aa-cec7-6471ad26eca9"
      },
      "source": [
        "# counter = 0\n",
        "# correct = 0\n",
        "# with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "#   for inputs, labels in tepoch:\n",
        "#     inputs = inputs.to(device)\n",
        "#     labels = labels.to(device)\n",
        "#     pred = model(inputs).argmax(axis=1)\n",
        "#     # print(pred.shape, inputs.shape)\n",
        "#     # print(pred)\n",
        "#     correct +=  pred.sum()\n",
        "#     counter += pred.shape[0]\n",
        "\n",
        "# print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "100%|██████████| 50/50 [01:22<00:00,  1.65s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  100.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jgoj6e3mr5X",
        "outputId": "25e46051-4d88-412b-d429-525222afb3df"
      },
      "source": [
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/PGD_L2/Epsilon0.5'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['train', 'val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  \"\"\"\n",
            "100%|██████████| 50/50 [00:04<00:00, 10.34batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  100.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9v74m-cotyX",
        "outputId": "aa42faed-fd9d-479e-eedc-666bf690e2f3"
      },
      "source": [
        "#@title test C&W 0.5\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/C&W_L2/Epsilon0.5'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['train', 'val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [04:42<00:00,  5.65s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  86.5 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irhuDV0oqkNZ",
        "outputId": "03de6722-9708-4c1d-d17e-75bbd37572d5"
      },
      "source": [
        "#@title test PGD-L2 Epsilon=2\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/PGD_L2/Epsilon2'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [04:03<00:00,  4.86s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  82.6 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpKqJTvBsNVC",
        "outputId": "0dc8252c-4566-4d90-b420-067801a475e8"
      },
      "source": [
        "#@title test PGD-L2 Epsilon=0.3\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/PGD_L2/Epsilon0.3'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [05:41<00:00,  6.82s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  100.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_z32Xk3u7RP",
        "outputId": "c6fc7257-3d80-452d-fa0c-40343e8e4c7b"
      },
      "source": [
        "#@title test PGD-L2 Epsilon=0.1\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/PGD_L2/Epsilon0.1'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [05:23<00:00,  6.48s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  100.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGb-UdFHsmlq",
        "outputId": "3375d744-03b5-4f8e-c727-ef420c115ab8"
      },
      "source": [
        "#@title test FGSM-L2 Epsilon=0.1\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/FGSM/Epsilon0.1'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [05:33<00:00,  6.67s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  0.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvgo1w2ZvmhM",
        "outputId": "3a30cb8b-dd57-4c9c-f88b-8fc9e99e4b71"
      },
      "source": [
        "#@title test FGSM-L2 Epsilon=0.01\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/FGSM/Epsilon0.01'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [06:01<00:00,  7.23s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  0.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CBFbKSCx6QG",
        "outputId": "b787038b-1e00-4069-a271-b66aed276972"
      },
      "source": [
        "#@title test pgd-Linf Epsilon=0.01\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/PGD_Linf/Epsilon0.01'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [04:43<00:00,  5.68s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  1.8 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikcvyrrpyweE",
        "outputId": "ca37e1c7-18fd-45c7-b094-77697a14bbb1"
      },
      "source": [
        "#@title test pgd-Linf Epsilon=0.005\n",
        "\n",
        "class fft(object):\n",
        "  def __call__(self, sample):\n",
        "    sample = torch.fft.fft2(sample)\n",
        "    sample = torch.fft.fftshift(sample,dim=(-2,-1))\n",
        "    return sample.float()\n",
        "\n",
        "#@title Dataloader Init\n",
        "transform = {\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        fft()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/598dataset/TinyImgNet_AdvSamples/VIT/PGD_Linf/Epsilon0.005'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform[x])\n",
        "                  for x in ['val']}\n",
        "                  \n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "              for x in ['val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# get some constants\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "with tqdm(dataloaders['val'], unit='batch') as tepoch:\n",
        "  for inputs, labels in tepoch:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(inputs).argmax(axis=1)\n",
        "    # print(pred.shape, inputs.shape)\n",
        "    # print(pred)\n",
        "    correct +=  pred.shape[0] - pred.sum()\n",
        "    counter += pred.shape[0]\n",
        "\n",
        "print(f\"clean accuracy:  {correct/counter * 100:.1f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
            "  import sys\n",
            "100%|██████████| 50/50 [04:30<00:00,  5.41s/batch]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "clean accuracy:  100.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}